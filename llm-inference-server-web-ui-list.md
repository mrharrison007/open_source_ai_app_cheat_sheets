# LLM Inference Server WEB UI List 



https://github.com/huggingface/chat-ui - Amazing clean UI with very good web search, my go to currently. (they added the ability to do it all locally very recently!)  

https://github.com/oobabooga/text-generation-webui - Best overall, supports any model format and has many extensions  

https://github.com/ParisNeo/lollms-webui/ - Has PDF, stable diffusion and web search integration  

https://github.com/h2oai/h2ogpt - Has PDF, Web search, best for files ingestion (supports many file formats)  

https://github.com/SillyTavern/SillyTavern - Best for custom characters and roleplay  

https://github.com/NimbleBoxAI/ChainFury - Has great UI and web search (experimental)  

https://github.com/nomic-ai/gpt4all - Basic UI that replicated ChatGPT  

https://github.com/imartinez/privateGPT - Basic UI that replicated ChatGPT with PDF integration  

https://github.com/LostRuins/koboldcpp  - Easy to install and simple interface  

#### LM Studio - Clean UI, focuses on GGUF format  

https://github.com/lobehub/lobe-chat  - Nice rich UI with the ability to load extensions for web search, TTS and more  

https://github.com/ollama-webui/ollama-webui - ChatGPT like UI with easy way to download models  

https://github.com/turboderp/exui - very fast and vram efficient  

https://github.com/PromtEngineer/localGPT - Focuses on PDF files  

https://github.com/shinomakoi/AI-Messenger  - Supports EXLv2 and LLava

https://github.com/serge-chat/serge



### Sources:

https://www.reddit.com/r/LocalLLaMA/comments/1847qt6/llm_webui_recommendations/



